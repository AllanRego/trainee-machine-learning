{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbors Classifier (k-NN)\n",
    "\n",
    "O **k-NN** é o classificador mais simples na área de aprendizado de máquina. Diferentemente das redes neurais, não se realiza de fato um **aprendizado**, em vez disso, o algoritmo verifica a distância entre o objeto a ser classificado e os vetores de característica. Devido a sua simplicidade, é bastante utilizado em *benchmarks* de classificadores mais complexos como, Artificial Neural Network (**ANN**) e Suport Vector Machine (**SVM**).\n",
    "\n",
    "<center>\n",
    "<figure>\n",
    "    <img src=\"notebook-images/classifier_comparison.png\" alt=\"Classifier Comparison\">\n",
    "    <figcaption>Figura 1 - Comparação entre os classificadores (https://amueller.github.io/applied_ml_spring_2017/images/classifier_comparison.png).</figcaption>\n",
    "</figure>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introdução\n",
    "\n",
    "O **k-NN** não passa por um processo de aprendizagem como o **ANN** e **SVM**, contudo existe um mecanismo de *mapeamento* que servirá para criar o modelo utilizado na classificação dos dados. Este modelo consiste numa lista de **descritores**, que tratam-se de listas das características que descrevem os exemplos dos modelos.\n",
    "\n",
    "<center>\n",
    "    <img src=\"notebook-images/descritor1.jpg\" width=\"450\" height=\"450\" style=\"float:left\">\n",
    "    <img src=\"notebook-images/descritor2.gif\"  width=\"400\" height=\"400\" style=\"float:right\">\n",
    "    <figcaption style=\"clear:both\">Figura 2 - Exemplos de descritores (vetores de características) de imagens.</figcaption>\n",
    "</center>\n",
    "\n",
    "A Figura 2 mostra exemplos de vetores de características sobre imagens, onde cada pixel se torna um elemento do vetor. Portanto cada imagem será representado por seu vetor característico correspondente, o qual fará parte de um conjunto de vetores que serão utilizados no processo de classificação. Além desse tipo de vetor característica, os elementos desses vetores podem ser nominais ou reais, como: **cor, preço, ano, altura, peso, estado civil, etc**. Outra informação relevante é que cada vetor possui uma **classe** associada, o qual servirá de referência para classificar os dados. A Figura 3 mostra a forma geral de um conjunto de descritores e suas repectivas classes. \n",
    "\n",
    "<center>\n",
    "    <img src=\"notebook-images/dataset_description.jpg\" width=\"500\"/>\n",
    "    <figcaption>Figura 3 - Conjunto de descritores genérico.</figcaption>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Obtenção dos dados\n",
    "\n",
    "Neste problema será utilizado o *dataset* <a href=\"http://archive.ics.uci.edu/ml/datasets/Iris\">Iris</a>, que consiste em um conjunto de dados que visa classificar os tipos de flores Ísis em **Setosa, Versicolour e Virginica**. Esse dataset é composto por 150 instâncias, sendo 50 para cada classe. Estes descritores são formados por 4 atributos: **tamanho da sépala, largura da sépala, tamanho da pétala** e **largura da pétala**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       0    1    2    3               4\n",
      "0    5.1  3.5  1.4  0.2     Iris-setosa\n",
      "1    4.9  3.0  1.4  0.2     Iris-setosa\n",
      "2    4.7  3.2  1.3  0.2     Iris-setosa\n",
      "3    4.6  3.1  1.5  0.2     Iris-setosa\n",
      "4    5.0  3.6  1.4  0.2     Iris-setosa\n",
      "5    5.4  3.9  1.7  0.4     Iris-setosa\n",
      "6    4.6  3.4  1.4  0.3     Iris-setosa\n",
      "7    5.0  3.4  1.5  0.2     Iris-setosa\n",
      "8    4.4  2.9  1.4  0.2     Iris-setosa\n",
      "9    4.9  3.1  1.5  0.1     Iris-setosa\n",
      "10   5.4  3.7  1.5  0.2     Iris-setosa\n",
      "11   4.8  3.4  1.6  0.2     Iris-setosa\n",
      "12   4.8  3.0  1.4  0.1     Iris-setosa\n",
      "13   4.3  3.0  1.1  0.1     Iris-setosa\n",
      "14   5.8  4.0  1.2  0.2     Iris-setosa\n",
      "15   5.7  4.4  1.5  0.4     Iris-setosa\n",
      "16   5.4  3.9  1.3  0.4     Iris-setosa\n",
      "17   5.1  3.5  1.4  0.3     Iris-setosa\n",
      "18   5.7  3.8  1.7  0.3     Iris-setosa\n",
      "19   5.1  3.8  1.5  0.3     Iris-setosa\n",
      "20   5.4  3.4  1.7  0.2     Iris-setosa\n",
      "21   5.1  3.7  1.5  0.4     Iris-setosa\n",
      "22   4.6  3.6  1.0  0.2     Iris-setosa\n",
      "23   5.1  3.3  1.7  0.5     Iris-setosa\n",
      "24   4.8  3.4  1.9  0.2     Iris-setosa\n",
      "25   5.0  3.0  1.6  0.2     Iris-setosa\n",
      "26   5.0  3.4  1.6  0.4     Iris-setosa\n",
      "27   5.2  3.5  1.5  0.2     Iris-setosa\n",
      "28   5.2  3.4  1.4  0.2     Iris-setosa\n",
      "29   4.7  3.2  1.6  0.2     Iris-setosa\n",
      "..   ...  ...  ...  ...             ...\n",
      "120  6.9  3.2  5.7  2.3  Iris-virginica\n",
      "121  5.6  2.8  4.9  2.0  Iris-virginica\n",
      "122  7.7  2.8  6.7  2.0  Iris-virginica\n",
      "123  6.3  2.7  4.9  1.8  Iris-virginica\n",
      "124  6.7  3.3  5.7  2.1  Iris-virginica\n",
      "125  7.2  3.2  6.0  1.8  Iris-virginica\n",
      "126  6.2  2.8  4.8  1.8  Iris-virginica\n",
      "127  6.1  3.0  4.9  1.8  Iris-virginica\n",
      "128  6.4  2.8  5.6  2.1  Iris-virginica\n",
      "129  7.2  3.0  5.8  1.6  Iris-virginica\n",
      "130  7.4  2.8  6.1  1.9  Iris-virginica\n",
      "131  7.9  3.8  6.4  2.0  Iris-virginica\n",
      "132  6.4  2.8  5.6  2.2  Iris-virginica\n",
      "133  6.3  2.8  5.1  1.5  Iris-virginica\n",
      "134  6.1  2.6  5.6  1.4  Iris-virginica\n",
      "135  7.7  3.0  6.1  2.3  Iris-virginica\n",
      "136  6.3  3.4  5.6  2.4  Iris-virginica\n",
      "137  6.4  3.1  5.5  1.8  Iris-virginica\n",
      "138  6.0  3.0  4.8  1.8  Iris-virginica\n",
      "139  6.9  3.1  5.4  2.1  Iris-virginica\n",
      "140  6.7  3.1  5.6  2.4  Iris-virginica\n",
      "141  6.9  3.1  5.1  2.3  Iris-virginica\n",
      "142  5.8  2.7  5.1  1.9  Iris-virginica\n",
      "143  6.8  3.2  5.9  2.3  Iris-virginica\n",
      "144  6.7  3.3  5.7  2.5  Iris-virginica\n",
      "145  6.7  3.0  5.2  2.3  Iris-virginica\n",
      "146  6.3  2.5  5.0  1.9  Iris-virginica\n",
      "147  6.5  3.0  5.2  2.0  Iris-virginica\n",
      "148  6.2  3.4  5.4  2.3  Iris-virginica\n",
      "149  5.9  3.0  5.1  1.8  Iris-virginica\n",
      "\n",
      "[150 rows x 5 columns]\n",
      "Iris-setosa: 50\n",
      "Iris-versicolor: 50\n",
      "Iris-virginica: 50\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregando o dataset\n",
    "dataset = pd.read_csv(\"dataset/iris/dataset.csv\", header=None)\n",
    "\n",
    "class_column = len (dataset.columns) - 1\n",
    "\n",
    "# Checando os dados\n",
    "print (dataset)\n",
    "\n",
    "# Descobrindo o número de instâncias por classes\n",
    "for i in pd.unique(dataset[class_column]):\n",
    "    print( i + ': ' + str(len (dataset.loc[dataset[class_column] == i])) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Princípio de funcionamento\n",
    "\n",
    "A ideia básica do classificador **k-NN** está em medir a *distância* entre o indivíduo a ser classificado e os descritores, onde a classe atribuida a esse indivíduo será a mesma que a maioria dos **k** descritores mais próximos. Existem vários cálculos de distâncias que podem ser utilizados como métricas para encontrar os descritores mais próximos, sendo as mais conhecidas a *Distância Euclidiana* e a *Distância Manhattan*. \n",
    "\n",
    "<center>\n",
    "    <img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/795b967db2917cdde7c2da2d1ee327eb673276c0\" width=\"450\">\n",
    "    <figcaption style=\"clear:both\">Equação 1 - Fórmula da Distância Euclidiana.</figcaption>\n",
    "    <img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/02436c34fc9562eb170e2e2cfddbb3303075b28e\"  width=\"400\">\n",
    "    <figcaption style=\"clear:both\">Equação 2 - Fórmula da Distância Manhattan.</figcaption>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Criando as funções para cálculos de distâncias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "\n",
    "def euclidean(p, q):\n",
    "    if len(p) != len (q):\n",
    "        return -1\n",
    "    \n",
    "    local_sum = 0\n",
    "    for i in range(0, len(p)):\n",
    "        local_sum += pow(q[i] - p[i], 2)\n",
    "    \n",
    "    return sqrt (local_sum)\n",
    "\n",
    "def manhattan(p, q):\n",
    "    if len(p) != len (q):\n",
    "        return -1\n",
    "    \n",
    "    local_sum = 0\n",
    "    for i in range(0, len(p)):\n",
    "        local_sum += abs(p[i] - q[i])\n",
    "    \n",
    "    return local_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pré-processamento\n",
    "\n",
    "O processo geral de implementação do **k-NN** segue as seguintes etapas:\n",
    "\n",
    "<ul>\n",
    "    <li>\n",
    "        <strong>Etapa 1: </strong>\n",
    "        Obter os dados, assim como verificar a precisão dos dados, realizar correções e remoção de dados desnecessários.\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Etapa 2: </strong>\n",
    "        Separar o conjunto de dados em 2 conjuntos: <i>treino</i> e <i>testes</i>, sendo o primeiro composto por cerca de 60%-85% do total, e o segundo com o restante.\n",
    "    </li>\n",
    "    <li>\n",
    "        <strong>Etapa 3: </strong>\n",
    "        Realizar a classificação, seguindo o princípio de funcionamento descrito acima.\n",
    "    </li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Embaralhando os dados\n",
    "dataset = dataset.iloc[np.random.permutation(len(dataset))]\n",
    "\n",
    "# Separando o dataset por classes\n",
    "setosa     = dataset.loc[dataset[class_column] == 'Iris-setosa']\n",
    "versicolor = dataset.loc[dataset[class_column] == 'Iris-versicolor']\n",
    "virginica  = dataset.loc[dataset[class_column] == 'Iris-virginica']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_percentage = 0.75\n",
    "\n",
    "# Obtendo os conjuntos de treino e de testes\n",
    "trainset = pd.concat([    setosa[0: int (len(setosa)     * train_percentage + 1)],\n",
    "                      versicolor[0: int (len(versicolor) * train_percentage + 1)],\n",
    "                       virginica[0: int (len(virginica)  * train_percentage + 1)]])\n",
    "\n",
    "testset =  pd.concat([    setosa[int (len(setosa)     * train_percentage + 1) : ],\n",
    "                      versicolor[int (len(versicolor) * train_percentage + 1) : ],\n",
    "                       virginica[int (len(virginica)  * train_percentage + 1) : ]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 1, acc = 0.9722222222222222\n",
      "K = 2, acc = 0.9722222222222222\n",
      "K = 3, acc = 1.0\n",
      "K = 4, acc = 0.9722222222222222\n",
      "K = 5, acc = 1.0\n",
      "K = 6, acc = 0.9722222222222222\n",
      "K = 7, acc = 0.9722222222222222\n",
      "K = 8, acc = 0.9722222222222222\n",
      "K = 9, acc = 1.0\n",
      "K = 10, acc = 0.9722222222222222\n",
      "K = 11, acc = 0.9722222222222222\n",
      "K = 12, acc = 0.9722222222222222\n",
      "K = 13, acc = 0.9722222222222222\n",
      "K = 14, acc = 0.9722222222222222\n",
      "K = 15, acc = 0.9722222222222222\n",
      "K = 16, acc = 0.9722222222222222\n",
      "K = 17, acc = 0.9722222222222222\n",
      "K = 18, acc = 0.9722222222222222\n",
      "K = 19, acc = 1.0\n",
      "K = 20, acc = 0.9722222222222222\n",
      "K = 21, acc = 0.9722222222222222\n",
      "K = 22, acc = 0.9722222222222222\n",
      "K = 23, acc = 0.9444444444444444\n",
      "K = 24, acc = 0.9722222222222222\n",
      "K = 25, acc = 0.9444444444444444\n",
      "K = 26, acc = 0.9444444444444444\n",
      "K = 27, acc = 0.9444444444444444\n",
      "K = 28, acc = 0.9444444444444444\n",
      "K = 29, acc = 0.9166666666666666\n",
      "K = 30, acc = 0.9166666666666666\n",
      "K = 31, acc = 0.9166666666666666\n",
      "K = 32, acc = 0.9444444444444444\n",
      "K = 33, acc = 0.9166666666666666\n",
      "K = 34, acc = 0.9722222222222222\n",
      "K = 35, acc = 0.9444444444444444\n",
      "K = 36, acc = 0.9722222222222222\n",
      "K = 37, acc = 0.9444444444444444\n",
      "K = 38, acc = 0.9444444444444444\n",
      "K = 39, acc = 0.9166666666666666\n",
      "K = 40, acc = 0.9444444444444444\n",
      "K = 41, acc = 0.9166666666666666\n",
      "K = 42, acc = 0.9166666666666666\n",
      "K = 43, acc = 0.9166666666666666\n",
      "K = 44, acc = 0.9166666666666666\n",
      "K = 45, acc = 0.9166666666666666\n",
      "K = 46, acc = 0.9166666666666666\n",
      "K = 47, acc = 0.9166666666666666\n",
      "K = 48, acc = 0.9166666666666666\n",
      "K = 49, acc = 0.8888888888888888\n",
      "K = 50, acc = 0.8888888888888888\n",
      "K = 51, acc = 0.8888888888888888\n",
      "K = 52, acc = 0.9166666666666666\n",
      "K = 53, acc = 0.8888888888888888\n",
      "K = 54, acc = 0.9166666666666666\n",
      "K = 55, acc = 0.9166666666666666\n",
      "K = 56, acc = 0.9166666666666666\n",
      "K = 57, acc = 0.8888888888888888\n",
      "K = 58, acc = 0.8888888888888888\n",
      "K = 59, acc = 0.8888888888888888\n",
      "K = 60, acc = 0.9166666666666666\n",
      "K = 61, acc = 0.8611111111111112\n",
      "K = 62, acc = 0.8611111111111112\n",
      "K = 63, acc = 0.8611111111111112\n",
      "K = 64, acc = 0.8611111111111112\n",
      "K = 65, acc = 0.8333333333333334\n",
      "K = 66, acc = 0.8333333333333334\n",
      "K = 67, acc = 0.8333333333333334\n",
      "K = 68, acc = 0.8611111111111112\n",
      "K = 69, acc = 0.8333333333333334\n",
      "K = 70, acc = 0.8333333333333334\n",
      "K = 71, acc = 0.8333333333333334\n",
      "K = 72, acc = 0.9166666666666666\n",
      "K = 73, acc = 0.8888888888888888\n",
      "K = 74, acc = 0.8888888888888888\n",
      "K = 75, acc = 0.8333333333333334\n",
      "K = 76, acc = 0.9444444444444444\n",
      "K = 77, acc = 0.9444444444444444\n",
      "K = 78, acc = 0.9444444444444444\n",
      "K = 79, acc = 0.9444444444444444\n",
      "K = 80, acc = 0.9444444444444444\n",
      "K = 81, acc = 0.9166666666666666\n",
      "K = 82, acc = 0.9444444444444444\n",
      "K = 83, acc = 0.9444444444444444\n",
      "K = 84, acc = 0.9444444444444444\n",
      "K = 85, acc = 0.9722222222222222\n",
      "K = 86, acc = 0.9444444444444444\n",
      "K = 87, acc = 0.9722222222222222\n",
      "K = 88, acc = 0.9722222222222222\n",
      "K = 89, acc = 0.9722222222222222\n",
      "K = 90, acc = 0.9722222222222222\n",
      "K = 91, acc = 0.9722222222222222\n",
      "K = 92, acc = 0.9722222222222222\n",
      "K = 93, acc = 0.9722222222222222\n",
      "K = 94, acc = 0.9722222222222222\n",
      "K = 95, acc = 0.9722222222222222\n",
      "K = 96, acc = 0.9722222222222222\n",
      "K = 97, acc = 0.9722222222222222\n",
      "K = 98, acc = 0.9722222222222222\n",
      "K = 99, acc = 0.9722222222222222\n",
      "K = 100, acc = 0.9722222222222222\n",
      "K = 101, acc = 0.9722222222222222\n",
      "K = 102, acc = 0.9722222222222222\n",
      "K = 103, acc = 0.9722222222222222\n",
      "K = 104, acc = 0.9722222222222222\n",
      "K = 105, acc = 0.9722222222222222\n",
      "K = 106, acc = 0.9722222222222222\n",
      "K = 107, acc = 0.9722222222222222\n",
      "K = 108, acc = 0.9722222222222222\n",
      "K = 109, acc = 0.9722222222222222\n",
      "K = 110, acc = 0.9722222222222222\n",
      "K = 111, acc = 0.9722222222222222\n",
      "K = 112, acc = 0.9722222222222222\n",
      "K = 113, acc = 0.9722222222222222\n",
      "K = 114, acc = 0.9722222222222222\n",
      "K = 115, acc = 0.9722222222222222\n",
      "K = 116, acc = 0.9722222222222222\n",
      "K = 117, acc = 0.9722222222222222\n",
      "K = 118, acc = 0.9722222222222222\n",
      "K = 119, acc = 0.9722222222222222\n",
      "K = 120, acc = 0.9722222222222222\n",
      "K = 121, acc = 0.9722222222222222\n",
      "K = 122, acc = 0.9722222222222222\n",
      "K = 123, acc = 0.9722222222222222\n",
      "K = 124, acc = 0.9722222222222222\n",
      "K = 125, acc = 0.9722222222222222\n",
      "K = 126, acc = 0.9722222222222222\n",
      "K = 127, acc = 0.9722222222222222\n",
      "K = 128, acc = 0.9722222222222222\n",
      "K = 129, acc = 0.9722222222222222\n",
      "K = 130, acc = 0.9722222222222222\n",
      "K = 131, acc = 0.9722222222222222\n",
      "K = 132, acc = 0.9722222222222222\n",
      "K = 133, acc = 0.9722222222222222\n",
      "K = 134, acc = 0.9722222222222222\n",
      "K = 135, acc = 0.9722222222222222\n",
      "K = 136, acc = 0.9722222222222222\n",
      "K = 137, acc = 0.9722222222222222\n",
      "K = 138, acc = 0.9722222222222222\n",
      "K = 139, acc = 0.9722222222222222\n",
      "K = 140, acc = 0.9722222222222222\n",
      "K = 141, acc = 0.9722222222222222\n",
      "K = 142, acc = 0.9722222222222222\n",
      "K = 143, acc = 0.9722222222222222\n",
      "K = 144, acc = 0.9722222222222222\n",
      "K = 145, acc = 0.9722222222222222\n",
      "K = 146, acc = 0.9722222222222222\n",
      "K = 147, acc = 0.9722222222222222\n",
      "K = 148, acc = 0.9722222222222222\n",
      "K = 149, acc = 0.9722222222222222\n",
      "K = 150, acc = 0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "from operator import itemgetter\n",
    "from collections import Counter\n",
    "\n",
    "# Criando a função de classificação\n",
    "def knn(k, trainset, element):\n",
    "    distance = []\n",
    "    \n",
    "    for _, row in trainset.iterrows():\n",
    "        distance.append((manhattan(row[0:class_column], element[0:class_column]), row[class_column]))\n",
    "    \n",
    "    distance.sort(key=itemgetter(0))\n",
    "    distance = [classes[1] for classes in distance[0:k]]\n",
    "    \n",
    "    most_common = Counter(distance)\n",
    "    #print(\"Classification: \" + max(most_common, key=most_common.get) + \", \" + element[4])\n",
    "    return max(most_common, key=most_common.get)\n",
    "\n",
    "# Função de avaliação de acurácia\n",
    "def evaluate(k, trainset, testset):\n",
    "    acc = 0\n",
    "    for _, row in testset.iterrows():\n",
    "        if( knn(k, trainset, row) == row[class_column] ):\n",
    "            acc += 1\n",
    "    \n",
    "    return acc / len(testset)\n",
    "\n",
    "# Descobrindo a acurácia para todas as configurações possíveis\n",
    "def evaluate_by_config(trainset, testset):\n",
    "    for k in range(1,len(dataset) + 1):\n",
    "        print(\"K = \" + str(k) + \", acc = \" + str(evaluate(k, trainset, testset)))\n",
    "        \n",
    "evaluate_by_config(trainset, testset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referências\n",
    "\n",
    "[1] Kevin Zakka. A Complete Guide to K-Nearest-Neighbors with Applications in Python and R, Available at: https://kevinzakka.github.io/2016/07/13/k-nearest-neighbor/ (Accessed: 28th March 2018).\n",
    "\n",
    "[2] Maxwell. Aprendizado de máquina - conceitos básicos, Available at: https://www.maxwell.vrac.puc-rio.br/25796/25796_4.PDF (Accessed: 28th March 2018).\n",
    "\n",
    "[3] Wikipedia (24th February 2018) k-nearest neighbors algorithm, Available at: https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm (Accessed: 28th March 2018)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
